<% @node[:varnish][:app_proxy_host].each_with_index do |host, i| %>
backend app_server_<%= i+1 %> {
  .host = "<%= host %>";
  .port = "<%= @node[:varnish][:app_proxy_port] %>";
  .probe = {
             .url = "<%= @node[:varnish][:app_proxy_host_probe_url] %>";
             .interval = 5s;
             .timeout = 1 s;
             .window = 5;
             .threshold = 3;
  }
}
<% end %>

<% if @node[:chef][:roles].include?('proxy') %>
backend static_server {
  .host = "<%= @node[:varnish][:static_proxy_host] %>";
  .port = "<%= @node[:varnish][:static_proxy_port] %>";
}

director app_director round-robin {
  <% @node[:varnish][:app_proxy_host].each_with_index do |host, i| %>
    { .backend = app_server_<%= i+1 %>; }
  <% end %>
}
<% end %>

sub vcl_recv {
    # Reject Non-RFC2616 or CONNECT or TRACE requests.
    if (req.request != "GET" &&
      req.request != "HEAD" &&
      req.request != "PUT" &&
      req.request != "POST" &&
      req.request != "OPTIONS" &&
      req.request != "DELETE") {
        return (pipe);
    }
    
    # Compression handled upstream; only want one in the cache
    if (req.http.Accept-Encoding) {
        remove req.http.Accept-Encoding;
    }
  
    # serve slightly stale content while a fresh version is fetched
    # better user experience and no thread pile up on the app servers
    set req.grace = 24h;
  
    # set the backend server based on request (if multi-server stack)
  <% if @node[:chef][:roles].include?('staging') %>
    set req.backend = app_server_1;
  <% elsif @node[:chef][:roles].include?('proxy') %>
    if (req.url ~ "^(/images|/javascripts|/flash|/stylesheets|/sitemap|/articles/html|/articles/xml|/regulations/html)") {
      set req.backend = static_server;
      return (lookup);
    } else {
      set req.backend = app_director;
    }
  <% end %>
    
  
    # NOT NEEDED WHEN USING A PROXY SERVER IN FRONT LIKE NGINX
    # Add a unique header containing the client address
    # remove req.http.X-Forwarded-For;
    # set    req.http.X-Forwarded-For = client.ip;
    
    # Pass POSTs etc directly on to the backend
    if (req.request != "GET" && req.request != "HEAD") {
        return (pass);
    }
    
    # Pass admin requests directly on to the backend
    if (req.url ~ "^/admin/") {
        return (pass);
    }

    # Prevent duplication of caches
    set req.http.host = "www.<%= @node[:varnish][:proxy_host_name] %>";
    
    # Check to see if cached
    return (lookup);
}

sub vcl_fetch {
    # Remove cache headers from going out to client; cache headers are being used for
    # varnish, not browser/upstream caches.
    # Actual browser/upstream cache is being set by the nginx proxy in front of varnish
    unset beresp.http.Cache-Control;
    
    # The following two sections give 'not accessible' errors...commenting out for now...
    
    # serve slightly stale content while a fresh version is fetched
    # better user experience and no thread pile up on the app servers
    set beresp.grace = 24h;
    
    # Directly serve static content
    if (req.url ~ "^(/images|/javascripts|/flash|/stylesheets|/sitemap|/articles/html|/articles/xml|/regulations/html)") {
        return(deliver);
    }
    # ESI process the rest
    else {
        esi;
    }
}

# vcl_hash creates the key for varnish under which the object is stored. It is
# possible to store the same url under 2 different keys, by making vcl_hash
# create a different hash.
sub vcl_hash {

    # these 2 entries are the default ones used for vcl. Below we add our own.
    set req.hash += req.url;
    set req.hash += req.http.host;
    
    # Hash differently based on presence of javascript_enabled cookie.
    if( req.url ~ "^/articles/search/header" && req.http.Cookie ~ "javascript_enabled=1" ) {
        # add this fact to the hash
        set req.hash += "javascript enabled";
    }
    
    return(hash);
}